{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 14\n",
    "\n",
    "Name: Daniyal Ahmed  \n",
    "UID: U11469883\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Naive Bayes\n",
    "- Model Evaluation\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "| Attribute A | Attribute B | Attribute C | Class |\n",
    "|-------------|-------------|-------------|-------|\n",
    "| Yes         | Single      | High        | No    |\n",
    "| No          | Married     | Mid         | No    |\n",
    "| No          | Single      | Low         | No    |\n",
    "| Yes         | Married     | High        | No    |\n",
    "| No          | Divorced    | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| Yes         | Divorced    | High        | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "\n",
    "a) Compute the following probabilities:\n",
    "\n",
    "- P(Attribute A = Yes | Class = No)\n",
    "- P(Attribute B = Divorced | Class = Yes)\n",
    "- P(Attribute C = High | Class = No)\n",
    "- P(Attribute C = Mid | Class = Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A). $\\frac{3}{7}$\n",
    "B). $\\frac{1}{3}$\n",
    "C). $\\frac{2}{7}$\n",
    "D). $1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Classify the following unseen records:\n",
    "\n",
    "- (Yes, Married, Mid)\n",
    "- (No, Divorced, High)\n",
    "- (No, Single, High)\n",
    "- (No, Divorced, Low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A). Class = No\n",
    "B). Class = Yes\n",
    "C). Class = Yes\n",
    "D.) Class = Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "a) Write a function to generate the confusion matrix for a list of actual classes and a list of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1]\n",
      " [4 3]]\n"
     ]
    }
   ],
   "source": [
    "actual_class = [\"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\"]\n",
    "predicted_class = [\"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def confusion_matrix(actual, predicted):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP =0\n",
    "    TN = 0  \n",
    "    for i in range(len(actual)):\n",
    "        if(actual[i] == \"Yes\" and predicted[i] == \"Yes\"):\n",
    "            TP += 1\n",
    "\n",
    "        if(actual[i] == \"Yes\" and predicted[i] == \"No\"):\n",
    "            FN += 1\n",
    "\n",
    "        if(actual[i] == \"No\" and predicted[i]== \"No\"):\n",
    "            FP +=1\n",
    "\n",
    "        if(actual[i] == \"No\" and predicted[i] == \"Yes\"):\n",
    "            TN +=1\n",
    "\n",
    "    return np.array([[TP,FN],[FP,TN]])\n",
    "\n",
    "print(confusion_matrix(actual_class, predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Assume you have the following Cost Matrix:\n",
    "\n",
    "|            | predicted = Y | predicted = N |\n",
    "|------------|---------------|---------------|\n",
    "| actual = Y |       -1      |       5       |\n",
    "| actual = N |        10     |       0       |\n",
    "\n",
    "What is the cost of the above classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "43\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that takes in the actual values, the predictions, and a cost matrix and outputs a cost. Test it on the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(confusion_matrix, cost_matrix):\n",
    "    cost = 0\n",
    "    for i in range(len(confusion_matrix)):\n",
    "        for j in range(len(confusion_matrix)):\n",
    "            cost += confusion_matrix[i][j] *cost_matrix[i][j]\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Implement functions for the following:\n",
    "\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f-measure\n",
    "\n",
    "and apply them to the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "    total = 0\n",
    "    for i in range(len(confusion_matrix)):\n",
    "        total+= sum(confusion_matrix[i])\n",
    "\n",
    "    return (confusion_matrix[0][0] + confusion_matrix[1][1])/total\n",
    "\n",
    "\n",
    "\n",
    "def precision(confusion_matrix):\n",
    "    return confusion_matrix[0][0]/(confusion_matrix[0][0] + confusion_matrix[1][0])\n",
    "\n",
    "def recall(confusion_matrix):\n",
    "    return confusion_matrix[0][0] / (confusion_matrix[0][0] + confusion_matrix[0][1])\n",
    "\n",
    "def f_measure(confusion_matrix):\n",
    "    return 2 * (precision(confusion_matrix) * recall(confusion_matrix)) / (precision(confusion_matrix) + recall(confusion_matrix))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge (Midterm prep part 2)\n",
    "\n",
    "In this exercise you will update your submission to the titanic competition.\n",
    "\n",
    "a) First let's add new numerical features / columns to the datasets that might be related to the survival of individuals.\n",
    "\n",
    "- `has_cabin` should have a value of 0 if the `cabin` feature is `nan` and 1 otherwise\n",
    "- `family_members` should have the total number of family members (by combining `SibSp` and `Parch`)\n",
    "- `title_type`: from the title extracted from the name, we will categorize it into 2 types: `common` for titles that many passengers have, `rare` for titles that few passengers have. Map `common` to 1 and `rare` to 0. Describe what threshold you used to define `common` and `rare` titles and how you found it.\n",
    "- `fare_type`: using Kmeans clustering on the fare column, find an appropriate number of clusters / groups of similar fares. Using the clusters you created, `fare_price` should be an ordinal variable that represents the expensiveness of the fare. For example if you split fare into 3 clusters ( 0 - 15, 15 - 40, and 40+ ) then the `fare_price` value should be `0` for `fare` values 0 - 15, `1` for 15 - 40, and `2` for 40+.\n",
    "- Create an addition two numerical features of your invention that you think could be relevant to the survival of individuals.\n",
    "\n",
    "Note: The features must be numerical because the sklearn `DecisionTreeClassifier` can only take on numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9248035914702581\n",
      "{15: 458, 30: 198, 45: 62, 60: 48, 75: 24, 90: 39, 105: 3, 120: 14, 135: 3, 150: 4, 165: 8, 180: 0, 195: 0, 210: 0, 225: 1, 240: 3, 255: 1, 270: 5, 285: 0, 300: 0, 315: 0}\n",
      "{10: 64, 20: 114, 30: 406, 40: 154, 50: 85, 60: 41, 70: 16, 80: 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniyal-ahmed/.local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/daniyal-ahmed/.local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "dataset = pd.read_csv('train.csv')\n",
    "\n",
    "dataset['has cabin'] = dataset['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "\n",
    "dataset['family members'] = dataset['SibSp'] + dataset['Parch']\n",
    "\n",
    "titles = {}\n",
    "total = 0\n",
    "\n",
    "\n",
    "for i in dataset['Name']:\n",
    "    title = i.split(',')[1].split('.')[0].strip()\n",
    "    if title in titles:\n",
    "        titles[title] += 1\n",
    "    else:\n",
    "        titles[title] = 1\n",
    "\n",
    "    total += 1\n",
    "\n",
    "'''Overwhelming majority of the titles are Mr, Mrs, and Miss. about 92 %'''\n",
    "print((titles['Mr']+titles['Mrs']+titles['Miss'])/total)\n",
    "\n",
    "threshold = 1- (titles['Mr']+titles['Mrs']+titles['Miss'])/total\n",
    "\n",
    "\n",
    "'''If it is greater than the threshold then is common title otherwise it is rare title'''\n",
    "dataset['title_type'] = dataset['Name'].apply(lambda x: 0 if titles[x.split(',')[1].split('.')[0].strip()]/total > threshold else 1)\n",
    "\n",
    "#Easier to do this since it is a one dimensional array\n",
    "ranges = {}\n",
    "current_range = 15\n",
    "\n",
    "ranges[current_range] = 0\n",
    "\n",
    "\n",
    "fares = dataset['Fare'].tolist()\n",
    "\n",
    "fares.sort()\n",
    "for price in fares:\n",
    "    if price > current_range:\n",
    "        current_range += 15\n",
    "        ranges[current_range] = 0\n",
    "    else:\n",
    "        ranges[current_range] += 1\n",
    "\n",
    "print(ranges)\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(dataset[['Fare']])\n",
    "\n",
    "dataset['fare_type'] = kmeans.labels_   \n",
    "\n",
    "\n",
    "Ages = dataset['Age'].fillna(dataset['Age'].mean()).tolist()\n",
    "PassengerId = dataset['PassengerId'].tolist()\n",
    "\n",
    "for i in range(len(Ages)):\n",
    "    Ages[i] = [Ages[i], PassengerId[i]]\n",
    "\n",
    "\n",
    "ranges = {}\n",
    "\n",
    "Ages.sort(key=lambda x: x[0])\n",
    "\n",
    "\n",
    "Age_range = 10\n",
    "ranges[Age_range] = 0   \n",
    "for Age in Ages:\n",
    "    if Age[0] > Age_range:\n",
    "        Age_range += 10\n",
    "        ranges[Age_range] = 0\n",
    "    else:\n",
    "        ranges[Age_range] += 1\n",
    "\n",
    "\n",
    " \n",
    "print(ranges)\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(dataset[['Fare']])\n",
    "\n",
    "dataset['Sex'] = dataset['Sex'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "\n",
    "\n",
    "dataset['Age_range'] = kmeans.labels_   \n",
    "\n",
    "\n",
    "\n",
    "dataset['Alone'] = dataset['family members'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Using a method covered in class, tune the parameters of a decision tree model on the titanic dataset (containing all numerical features including the ones you added above). Evaluate this model locally and report it's performance.\n",
    "\n",
    "Note: make sure you are not tuning your parameters on the same dataset you are using to evaluate the model. Also explain how you know you are not overfitting to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7533632286995515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''We will use the following features to predict survival: Age_range, fare_type, title_type, has cabin, family members, has child, Pclass, Fare Aka all the \n",
    "numerial features'''\n",
    "X= dataset[['Age_range', 'fare_type', 'title_type', 'has cabin', 'family members', 'Alone', 'Pclass', 'Sex']]\n",
    "y= dataset['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='gini' ,random_state=1, max_depth=6)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions_dt = tree.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions_dt)\n",
    "print(f\"Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Try reducing the dimension of the dataset and create a Naive Bayes model. Evaluate this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6995515695067265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "'''Got PCA from the example code given below the challenge problem'''\n",
    "pca = PCA(n_components=5, whiten=True)\n",
    "\n",
    "X= dataset[['Age_range', 'fare_type', 'title_type', 'has cabin', 'family members', 'Alone','Pclass', 'Sex']]\n",
    "y= dataset['Survived']\n",
    "\n",
    "#X= pca.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the model, Assuming a normal distribution Since it can't possibly be discrete\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions_nb = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions_nb)\n",
    "print(f\"Model Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Create an ensemble classifier using a combination of KNN, Decision Trees, and Naive Bayes models. Evaluate this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7354260089686099\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "'''Had to do some googling since this part wasn't covered in last class, but I first googled what an essemble \n",
    "classifier is and found out that it was a way of combining models to get a better result. I found this function from \n",
    "scipy called mode, which takes the prediction of all three models and returns the most common prediction. I then used\n",
    "Its almost like a voting feature, the models vote on which one they think is more likely to be correct and the most common'''\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "predictions_knn = knn.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predictions_combined = np.array([predictions_knn, predictions_dt, predictions_nb])\n",
    "predictions_ensemble, _ = mode(predictions_combined, axis=0)\n",
    "accuracy = accuracy_score(y_test, predictions_ensemble.ravel())\n",
    "print(f\"Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Update your kaggle submission using the best model you created (best model means the one that performed the best on your local evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the essemble classifier since it combines it technically combines all three models prediction into one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9330143540669856\n",
      "{15: 215, 30: 92, 45: 24, 60: 22, 75: 13, 90: 14, 105: 1, 120: 1, 135: 2, 150: 3, 165: 3, 180: 0, 195: 0, 210: 0, 225: 4, 240: 0, 255: 0, 270: 6, 285: 0}\n",
      "{10: 22, 20: 46, 30: 130, 40: 140, 50: 45, 60: 19, 70: 9, 80: 0}\n",
      "[1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1\n",
      " 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniyal-ahmed/.local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/daniyal-ahmed/.local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "dataset = pd.read_csv('test.csv')\n",
    "\n",
    "dataset['has cabin'] = dataset['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "\n",
    "dataset['family members'] = dataset['SibSp'] + dataset['Parch']\n",
    "\n",
    "titles = {}\n",
    "total = 0\n",
    "\n",
    "\n",
    "for i in dataset['Name']:\n",
    "    title = i.split(',')[1].split('.')[0].strip()\n",
    "    if title in titles:\n",
    "        titles[title] += 1\n",
    "    else:\n",
    "        titles[title] = 1\n",
    "\n",
    "    total += 1\n",
    "\n",
    "'''Overwhelming majority of the titles are Mr, Mrs, and Miss. about 92 %'''\n",
    "print((titles['Mr']+titles['Mrs']+titles['Miss'])/total)\n",
    "\n",
    "threshold = 1- (titles['Mr']+titles['Mrs']+titles['Miss'])/total\n",
    "\n",
    "\n",
    "'''If it is greater than the threshold then is common title otherwise it is rare title'''\n",
    "dataset['title_type'] = dataset['Name'].apply(lambda x: 0 if titles[x.split(',')[1].split('.')[0].strip()]/total > threshold else 1)\n",
    "\n",
    "#Easier to do this since it is a one dimensional array\n",
    "ranges = {}\n",
    "current_range = 15\n",
    "\n",
    "ranges[current_range] = 0\n",
    "\n",
    "\n",
    "fares = dataset['Fare'].fillna(dataset['Fare'].mean()).tolist()\n",
    "dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].mean())\n",
    "fares.sort()\n",
    "for price in fares:\n",
    "    if price > current_range:\n",
    "        current_range += 15\n",
    "        ranges[current_range] = 0\n",
    "    else:\n",
    "        ranges[current_range] += 1\n",
    "\n",
    "print(ranges)\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(dataset[['Fare']])\n",
    "\n",
    "dataset['fare_type'] = kmeans.labels_   \n",
    "\n",
    "\n",
    "Ages = dataset['Age'].fillna(dataset['Age'].mean()).tolist()\n",
    "PassengerId = dataset['PassengerId'].tolist()\n",
    "\n",
    "for i in range(len(Ages)):\n",
    "    Ages[i] = [Ages[i], PassengerId[i]]\n",
    "\n",
    "\n",
    "ranges = {}\n",
    "\n",
    "Ages.sort(key=lambda x: x[0])\n",
    "\n",
    "\n",
    "Age_range = 10\n",
    "ranges[Age_range] = 0   \n",
    "for Age in Ages:\n",
    "    if Age[0] > Age_range:\n",
    "        Age_range += 10\n",
    "        ranges[Age_range] = 0\n",
    "    else:\n",
    "        ranges[Age_range] += 1\n",
    "\n",
    "\n",
    " \n",
    "print(ranges)\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(dataset[['Fare']])\n",
    "\n",
    "dataset['Sex'] = dataset['Sex'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "\n",
    "\n",
    "dataset['Age_range'] = kmeans.labels_   \n",
    "\n",
    "\n",
    "\n",
    "dataset['Alone'] = dataset['family members'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "\n",
    "test = dataset[['Age_range', 'fare_type', 'title_type', 'has cabin', 'family members', 'Alone','Pclass', 'Sex', ]]\n",
    "\n",
    "predictions_knn = knn.predict(test)\n",
    "predictions_nb = model.predict(test)\n",
    "predictions_dt = tree.predict(test)\n",
    "predictions_combined= [predictions_dt,predictions_nb,predictions_knn]\n",
    "\n",
    "#predictions_ensemble, _ = mode(predictions_combined, axis=0)\n",
    "\n",
    "print(predictions_ensemble)\n",
    "#Saving the CSV file\n",
    "csv = pd.DataFrame({\n",
    "    'PassengerId': dataset['PassengerId'],\n",
    "    'Survived': predictions_dt\n",
    "})\n",
    "\n",
    "csv.to_csv('sub.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful code for the midterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# Get face data\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "\n",
    "# plot face data\n",
    "fig, ax = plt.subplots(3, 5)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[],\n",
    "            xlabel=faces.target_names[faces.target[i]])\n",
    "plt.show()\n",
    "\n",
    "# split train test set\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target, random_state=42)\n",
    "\n",
    "pca = PCA(n_components=150, whiten=True)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "svcpca = make_pipeline(pca, svc)\n",
    "\n",
    "# Tune model to find best values of C and gamma using cross validation\n",
    "param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "kfold = 10\n",
    "grid = GridSearchCV(svcpca, param_grid, cv=kfold)\n",
    "grid.fit(Xtrain, ytrain)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "# use the best params explicitly here\n",
    "pca = PCA(n_components=150, whiten=True)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced', C=10, gamma=0.005)\n",
    "svcpca = make_pipeline(pca, svc)\n",
    "\n",
    "model = BaggingClassifier(svcpca, n_estimators=100).fit(Xtrain, ytrain)\n",
    "yfit = model.predict(Xtest)\n",
    "\n",
    "fig, ax = plt.subplots(6, 6)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],\n",
    "                   color='black' if yfit[i] == ytest[i] else 'red')\n",
    "fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14)\n",
    "plt.show()\n",
    "\n",
    "mat = confusion_matrix(ytest, yfit)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=faces.target_names,\n",
    "            yticklabels=faces.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy = \", accuracy_score(ytest, yfit))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
